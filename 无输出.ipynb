{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMqxCvf7JW9J"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install retina-face"
      ],
      "metadata": {
        "id": "pdtCbO6IJ2yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "def capFrame(videoPath, savePath,famename):\n",
        "    cap = cv2.VideoCapture(videoPath)\n",
        "    numFrame = 0\n",
        "    imagenum = int(cap.get(7)/60)\n",
        "    # print(imagenum)\n",
        "    while True:\n",
        "        if imagenum == 0:\n",
        "             break\n",
        "        if cap.grab():\n",
        "            numFrame += 1\n",
        "            # 每60桢截取一个图片\n",
        "            if numFrame % 60 == 1:\n",
        "                #retrieve 解码并返回一个桢\n",
        "                flag, frame = cap.retrieve()\n",
        "                cv2_imshow(frame)\n",
        "                newPath = savePath + str(famename)+ str(\"_\")+str(int(imagenum)) +\".jpg\"\n",
        "                # print(newPath)\n",
        "                cv2.imencode('.jpg', frame)[1].tofile(newPath)\n",
        "                imagenum -= 1\n",
        "       \n",
        "# capFrame(r\"C:\\Users\\fulian\\Desktop\\code and exp\\manipulated_sequences\\Face2Face\\c23\\videos\\023_923.mp4\",r\"C:\\Users\\fulian\\Desktop\\image\")\n"
      ],
      "metadata": {
        "id": "Tb_wBtXnJ-uB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "path_fake= \"/content/drive/MyDrive/Deepfakes/c23/videos\"  #待读取的文件夹\n",
        "path_list_fake=os.listdir(path_fake)\n",
        "for filename in path_list_fake:\n",
        "            m = str(os.path.splitext(filename)[0])\n",
        "            capFrame(os.path.join(path_fake,filename),\"/content/drive/MyDrive/picture/\",m)"
      ],
      "metadata": {
        "id": "_gkQOj6WKD5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "path= \"/content/drive/MyDrive/videos_original\"  #待读取的文件夹\n",
        "path_list=os.listdir(path)\n",
        "for filename in path_list:\n",
        "            m = str(os.path.splitext(filename)[0])\n",
        "            capFrame(os.path.join(path,filename),\"/content/drive/MyDrive/orignal_unextract/\",m)"
      ],
      "metadata": {
        "id": "KjytG_oXKZgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from retinaface import RetinaFace\n",
        "import torch\n",
        "import os\n",
        "import cv2\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "path='/content/drive/MyDrive/orignal_unextract'\n",
        "path_list=os.listdir(path)\n",
        "i = 0\n",
        "\n",
        "for filename in path_list:\n",
        "   m = str(os.path.splitext(filename)[0])\n",
        "   faces = RetinaFace.extract_faces(img_path = os.path.join(path,filename), align = True)\n",
        "   for face in faces:\n",
        "      plt.imshow(face)\n",
        "      savepath = '/content/drive/MyDrive/original_face_img/'+str(m)+'face'+'.jpg'\n",
        "      plt.savefig(savepath)\n",
        "      img = cv2.imread(savepath)\n",
        "      img = torch.tensor(img)\n",
        "      img = torch.unsqueeze(img,0)\n",
        "      # print(img.shape)\n",
        "      # img = torch.flatten(img,1,3)\n",
        "      img = img.permute(0,3,1,2)\n",
        "      #print(img.shape)\n",
        "      if i == 0:\n",
        "        org_set = img\n",
        "      elif i != 0:\n",
        "        org_set = torch.cat((org_set,img),0)\n",
        "      i += 1\n",
        "      plt.show()\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "EvxKkRLOKmG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from retinaface import RetinaFace\n",
        "import torch\n",
        "import os\n",
        "import cv2\n",
        "path='/content/drive/MyDrive/picture'\n",
        "path_list=os.listdir(path)\n",
        "j = 0\n",
        "\n",
        "for filename in path_list:\n",
        "   m = str(os.path.splitext(filename)[0])\n",
        "   faces = RetinaFace.extract_faces(img_path = os.path.join(path,filename), align = True)\n",
        "   for face in faces:\n",
        "      plt.imshow(face)\n",
        "      savepath = '/content/drive/MyDrive/fake_face_img/'+str(m)+'face'+'.jpg'\n",
        "      plt.savefig(savepath)\n",
        "      img = cv2.imread(savepath)\n",
        "      img = torch.tensor(img)\n",
        "      img = torch.unsqueeze(img,0)\n",
        "      # print(img.shape)\n",
        "      # img = torch.flatten(img,1,3)\n",
        "      img = img.permute(0,3,1,2)\n",
        "      print(img.shape)\n",
        "      # print(img)\n",
        "      if j == 0:\n",
        "        fake_set = img\n",
        "      elif j != 0:\n",
        "        fake_set = torch.cat((fake_set,img),0)\n",
        "      j += 1\n",
        "      plt.show()\n",
        "\n",
        "  \n",
        "  "
      ],
      "metadata": {
        "id": "KkuAWKHXLr65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as Data\n",
        "print(org_set.shape)\n",
        "print(i)\n",
        "length_ori = i\n",
        "# print(j)\n",
        "\n",
        "label_o = torch.ones(i)\n",
        "label_f = torch.zeros(j)\n",
        "\n",
        "dataset_t = torch.cat((fake_set,org_set),0)  \n",
        "\n",
        "print(dataset_t.shape)\n",
        "label = torch.cat((label_o,label_f),0) \n",
        "print(label.shape)\n",
        "dataset = Data.TensorDataset(dataset_t, label)\n",
        "#分割\n",
        "validation_split = .2\n",
        "random_seed= 42\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "np.random.seed(random_seed)\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "train_sampler = Data.SubsetRandomSampler(train_indices)\n",
        "valid_sampler = Data.SubsetRandomSampler(val_indices)\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=5, \n",
        "                                   sampler=train_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=5,\n",
        "                                   sampler=valid_sampler)\n",
        "# list(validation_loader)#"
      ],
      "metadata": {
        "id": "QWjdTKIZKz2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Author: Andreas Rössler\n",
        "\"\"\"\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "pretrained_settings = {\n",
        "    'xception': {\n",
        "        'imagenet': {\n",
        "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/xception-b5690688.pth',\n",
        "            'input_space': 'RGB',\n",
        "            'input_size': [3,240,320],\n",
        "            'input_range': [0, 1],\n",
        "            'mean': [0.5, 0.5, 0.5],\n",
        "            'std': [0.5, 0.5, 0.5],\n",
        "            'num_classes': 1000,\n",
        "            'scale': 0.8975  # The resize parameter of the validation transform should be 333, and make sure to center crop at 299x299\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "class SeparableConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False):\n",
        "        super(SeparableConv2d, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size,\n",
        "                               stride, padding, dilation, groups=in_channels, bias=bias)\n",
        "        self.pointwise = nn.Conv2d(\n",
        "            in_channels, out_channels, 1, 1, 0, 1, 1, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "class RegressionMap(nn.Module):\n",
        "    def __init__(self, c_in):\n",
        "        super(RegressionMap, self).__init__()\n",
        "        self.c = SeparableConv2d(c_in, 1, 3, stride=1, padding=1, bias=False)\n",
        "        self.s = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        mask = self.c(x)\n",
        "        mask = self.s(mask)\n",
        "        return mask\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_filters, out_filters, reps, strides=1, start_with_relu=True, grow_first=True):\n",
        "        super(Block, self).__init__()\n",
        "\n",
        "        if out_filters != in_filters or strides != 1:\n",
        "            self.skip = nn.Conv2d(in_filters, out_filters,\n",
        "                                  1, stride=strides, bias=False)\n",
        "            self.skipbn = nn.BatchNorm2d(out_filters)\n",
        "        else:\n",
        "            self.skip = None\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=False)\n",
        "        rep = []\n",
        "\n",
        "        filters = in_filters\n",
        "        if grow_first:   # whether the number of filters grows first\n",
        "            rep.append(self.relu)\n",
        "            rep.append(SeparableConv2d(in_filters, out_filters,\n",
        "                                       3, stride=1, padding=1, bias=False))\n",
        "            rep.append(nn.BatchNorm2d(out_filters))\n",
        "            filters = out_filters\n",
        "\n",
        "        for i in range(reps-1):\n",
        "            rep.append(self.relu)\n",
        "            rep.append(SeparableConv2d(filters, filters,\n",
        "                                       3, stride=1, padding=1, bias=False))\n",
        "            rep.append(nn.BatchNorm2d(filters))\n",
        "\n",
        "        if not grow_first:\n",
        "            rep.append(self.relu)\n",
        "            rep.append(SeparableConv2d(in_filters, out_filters,\n",
        "                                       3, stride=1, padding=1, bias=False))\n",
        "            rep.append(nn.BatchNorm2d(out_filters))\n",
        "\n",
        "        if not start_with_relu:\n",
        "            rep = rep[1:]\n",
        "        else:\n",
        "            rep[0] = nn.ReLU(inplace=False)\n",
        "\n",
        "        if strides != 1:\n",
        "            rep.append(nn.MaxPool2d(3, strides, 1))\n",
        "        self.rep = nn.Sequential(*rep)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        x = self.rep(inp)\n",
        "\n",
        "        if self.skip is not None:\n",
        "            skip = self.skip(inp)\n",
        "            skip = self.skipbn(skip)\n",
        "        else:\n",
        "            skip = inp\n",
        "\n",
        "        x += skip\n",
        "        return x\n",
        "\n",
        "\n",
        "class Xception(nn.Module):\n",
        "    \"\"\"\n",
        "    Xception optimized for the ImageNet dataset, as specified in\n",
        "    https://arxiv.org/pdf/1610.02357.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=1000, inc=3):\n",
        "        \"\"\" Constructor\n",
        "        Args:\n",
        "            num_classes: number of classes\n",
        "        \"\"\"\n",
        "        super(Xception, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Entry flow\n",
        "        self.conv1 = nn.Conv2d(inc, 32, 3, 2, 0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu = nn.ReLU(inplace=False)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        # do relu here\n",
        "\n",
        "        self.block1 = Block(\n",
        "            64, 128, 2, 2, start_with_relu=False, grow_first=True)\n",
        "        self.block2 = Block(\n",
        "            128, 256, 2, 2, start_with_relu=True, grow_first=True)\n",
        "        self.block3 = Block(\n",
        "            256, 728, 2, 2, start_with_relu=True, grow_first=True)\n",
        "\n",
        "        # middle flow\n",
        "        self.block4 = Block(\n",
        "            728, 728, 3, 1, start_with_relu=True, grow_first=True)\n",
        "        self.block5 = Block(\n",
        "            728, 728, 3, 1, start_with_relu=True, grow_first=True)\n",
        "        self.block6 = Block(\n",
        "            728, 728, 3, 1, start_with_relu=True, grow_first=True)\n",
        "        self.block7 = Block(\n",
        "            728, 728, 3, 1, start_with_relu=True, grow_first=True)\n",
        "\n",
        "        self.block8 = Block(\n",
        "            728, 728, 3, 1, start_with_relu=True, grow_first=True)\n",
        "        self.block9 = Block(\n",
        "            728, 728, 3, 1, start_with_relu=True, grow_first=True)\n",
        "        self.block10 = Block(\n",
        "            728, 728, 3, 1, start_with_relu=True, grow_first=True)\n",
        "        self.block11 = Block(\n",
        "            728, 728, 3, 1, start_with_relu=True, grow_first=True)\n",
        "\n",
        "        # Exit flow\n",
        "        self.block12 = Block(\n",
        "            728, 1024, 2, 2, start_with_relu=True, grow_first=False)\n",
        "\n",
        "        self.conv3 = SeparableConv2d(1024, 1536, 3, 1, 1)\n",
        "        self.bn3 = nn.BatchNorm2d(1536)\n",
        "\n",
        "        # do relu here\n",
        "        self.conv4 = SeparableConv2d(1536, 2048, 3, 1, 1)\n",
        "        self.bn4 = nn.BatchNorm2d(2048)\n",
        "\n",
        "        self.fc = nn.Linear(2048, num_classes)\n",
        "        self.type_fc = nn.Linear(2048, 5)\n",
        "        self.mag_fc = nn.Linear(2048, 1)\n",
        "        self.map = RegressionMap(728)\n",
        "        self.pecent= 1.0 / 1.5\n",
        "    def fea_part1_0(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)  \n",
        "\n",
        "        return x\n",
        "\n",
        "    def fea_part1_1(self, x):  \n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x) \n",
        "\n",
        "        return x\n",
        "    \n",
        "    def fea_part1(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)     \n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x) \n",
        "\n",
        "        return x\n",
        "    \n",
        "    def fea_part2(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def fea_part3(self, x):\n",
        "        x = self.block4(x)\n",
        "        x = self.block5(x)\n",
        "        x = self.block6(x)\n",
        "        x = self.block7(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def fea_part4(self, x):\n",
        "        x = self.block8(x)\n",
        "        x = self.block9(x)\n",
        "        x = self.block10(x)\n",
        "        x = self.block11(x)\n",
        "        x = self.block12(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def fea_part5(self, x):\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "\n",
        "        return x\n",
        "     \n",
        "    def features(self, input):\n",
        "        x = self.fea_part1(input)    \n",
        "\n",
        "        x = self.fea_part2(x)\n",
        "        x = self.fea_part3(x)\n",
        "        x = self.fea_part4(x)\n",
        "\n",
        "        x = self.fea_part5(x)\n",
        "        return x\n",
        "\n",
        "    #def classifier(self, features):\n",
        "    def classifier(self, x):\n",
        "        x = self.fea_part4(x)\n",
        "        x = self.fea_part5(x)\n",
        "        x = self.relu(x)\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        out = self.last_linear(x)\n",
        "        type = self.type_fc(x)\n",
        "        mag = self.mag_fc(x)\n",
        "        return out, x, type, mag\n",
        "\n",
        "    def estimateMap(self, x):\n",
        "        map = self.map(x)\n",
        "        return map\n",
        "\n",
        "    #def forward(self, input):\n",
        "    def forward(self, x):\n",
        "        x = self.fea_part1(x)\n",
        "        x = self.fea_part2(x)\n",
        "        x = self.fea_part3(x)\n",
        "        out, fea, type, mag = self.classifier(x)\n",
        "        map = self.estimateMap(x)\n",
        "        return out, fea, map, type, mag\n",
        "\n",
        "\n",
        "def xception(num_classes=1000, pretrained='imagenet', inc=3):\n",
        "    model = Xception(num_classes=num_classes, inc=inc)\n",
        "    if pretrained:\n",
        "        settings = pretrained_settings['xception'][pretrained]\n",
        "        assert num_classes == settings['num_classes'], \\\n",
        "            \"num_classes should be {}, but is {}\".format(\n",
        "                settings['num_classes'], num_classes)\n",
        "\n",
        "        model = Xception(num_classes=num_classes)\n",
        "        model.load_state_dict(model_zoo.load_url(settings['url']))\n",
        "\n",
        "        model.input_space = settings['input_space']\n",
        "        model.input_size = settings['input_size']\n",
        "        model.input_range = settings['input_range']\n",
        "        model.mean = settings['mean']\n",
        "        model.std = settings['std']\n",
        "\n",
        "    # TODO: ugly\n",
        "    model.last_linear = model.fc\n",
        "    del model.fc\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "class RPModel(nn.Module):\n",
        "    def __init__(self,modelchoice,num_out_classes=2,dropout=0.0):\n",
        "        super(RPModel, self).__init__()\n",
        "        self.modelchoice = modelchoice\n",
        "\n",
        "        if modelchoice == 'resnet50':\n",
        "            self.rmodel = torchvision.models.resnet50(pretrained=True)\n",
        "        elif modelchoice == 'resnet18':\n",
        "            self.rmodel = torchvision.models.resnet18(pretrained=True)\n",
        "        elif modelchoice == 'resnext':\n",
        "            self.rmodel = torchvision.models.resnext50_32x4d(pretrained=True)\n",
        "        elif modelchoice == 'inceptionv3':\n",
        "            self.rmodel = torchvision.models.inception_v3(pretrained=True)\n",
        "        # elif modelchoice == 'efficientB5':\n",
        "        #     self.rmodel = EfficientNet.from_pretrained('efficientnet-b5')\n",
        "        # elif modelchoice == 'efficientB7':\n",
        "        #     self.rmodel = EfficientNet.from_pretrained('efficientnet-b7')\n",
        "        else: \n",
        "            raise ValueError('No matching model...')\n",
        "\n",
        "\n",
        "        if modelchoice == 'efficientB5' or modelchoice == 'efficientB7':\n",
        "            num_ftrs = self.rmodel._fc.in_features\n",
        "            if not dropout:\n",
        "                self.rmodel._fc = nn.Linear(num_ftrs, num_out_classes)\n",
        "            else:\n",
        "                self.rmodel._fc = nn.Sequential(\n",
        "                    nn.Dropout(p=dropout),\n",
        "                    nn.Linear(num_ftrs, num_out_classes)\n",
        "                )\n",
        "        elif modelchoice == 'inceptionv3':\n",
        "            num_ftrs = self.rmodel.AuxLogits.fc.in_features\n",
        "            self.rmodel.AuxLogits.fc = nn.Linear(num_ftrs, num_out_classes)\n",
        "            num_ftrs = self.rmodel.fc.in_features\n",
        "            self.rmodel.fc = nn.Linear(num_ftrs,num_out_classes)\n",
        "        else:\n",
        "            num_ftrs = self.rmodel.fc.in_features\n",
        "            if not dropout:\n",
        "                self.rmodel.fc = nn.Linear(num_ftrs, num_out_classes)\n",
        "            else:\n",
        "                self.rmodel.fc = nn.Sequential(\n",
        "                    nn.Dropout(p=dropout),\n",
        "                    nn.Linear(num_ftrs, num_out_classes)\n",
        "                )\n",
        "\n",
        "\n",
        "    def features(self, input):\n",
        "        return None # logits \n",
        "\n",
        "    def classifier(self, features):\n",
        "        return None, None\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = self.rmodel(input)\n",
        "\n",
        "        return out, None\n",
        "\n",
        "\n",
        "class TransferModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple transfer learning model that takes an imagenet pretrained model with\n",
        "    a fc layer as base model and retrains a new fc layer for num_out_classes\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, modelchoice, num_out_classes=2, dropout=0.0, \n",
        "    weight_norm=False, return_fea=False, inc=3):\n",
        "        super(TransferModel, self).__init__()\n",
        "        self.modelchoice = modelchoice\n",
        "        self.return_fea = return_fea\n",
        "\n",
        "        if modelchoice == 'xception':\n",
        "\n",
        "            def return_pytorch04_xception(pretrained=True):\n",
        "                # Raises warning \"src not broadcastable to dst\" but thats fine\n",
        "                model = xception(pretrained=False)\n",
        "                if pretrained:\n",
        "                    # Load model in torch 0.4+\n",
        "                    model.fc = model.last_linear\n",
        "                    del model.last_linear\n",
        "                    state_dict = torch.load(\n",
        "                        '/content/drive/MyDrive/weights/xception-b5690688.pth')\n",
        "                    print('Loaded pretrained model (ImageNet)....')\n",
        "                    for name, weights in state_dict.items():\n",
        "                        if 'pointwise' in name:\n",
        "                            state_dict[name] = weights.unsqueeze(\n",
        "                                -1).unsqueeze(-1)\n",
        "                    model.load_state_dict(state_dict, strict=False)\n",
        "                    model.last_linear = model.fc\n",
        "                    del model.fc\n",
        "                return model\n",
        "\n",
        "            self.model = return_pytorch04_xception()\n",
        "            # Replace fc\n",
        "            num_ftrs = self.model.last_linear.in_features\n",
        "            if not dropout:\n",
        "                if weight_norm:\n",
        "                    print('Using Weight_Norm')\n",
        "                    self.model.last_linear = nn.utils.weight_norm(\n",
        "                        nn.Linear(num_ftrs, num_out_classes), name='weight')\n",
        "                self.model.last_linear = nn.Linear(num_ftrs, num_out_classes)\n",
        "            else:\n",
        "                print('Using dropout', dropout)\n",
        "                if weight_norm:\n",
        "                    print('Using Weight_Norm')\n",
        "                    self.model.last_linear = nn.Sequential(\n",
        "                        nn.Dropout(p=dropout),\n",
        "                        nn.utils.weight_norm(\n",
        "                            nn.Linear(num_ftrs, num_out_classes), name='weight')\n",
        "                    )\n",
        "\n",
        "                self.model.last_linear = nn.Sequential(\n",
        "                    nn.Dropout(p=dropout),\n",
        "                    nn.Linear(num_ftrs, num_out_classes)\n",
        "                )\n",
        "            \n",
        "            if inc != 3:\n",
        "                self.model.conv1 = nn.Conv2d(inc, 32, 3, 2, 0, bias=False)                \n",
        "                nn.init.xavier_normal_(self.model.conv1.weight.data, gain=0.02)\n",
        "\n",
        "        elif modelchoice == 'resnet50' or modelchoice == 'resnet18' \\\n",
        "            or modelchoice == 'resnext' or modelchoice == 'inceptionv3' \\\n",
        "            or modelchoice == 'efficientB5'or modelchoice == 'efficientB7':\n",
        "            \n",
        "            self.model = RPModel(modelchoice,num_out_classes,dropout)\n",
        "            \n",
        "        else:\n",
        "            raise Exception('Choose valid model, e.g. resnet50')\n",
        "\n",
        "    def set_trainable_up_to(self, boolean=False, layername=\"Conv2d_4a_3x3\"):\n",
        "        \"\"\"\n",
        "        Freezes all layers below a specific layer and sets the following layers\n",
        "        to true if boolean else only the fully connected final layer\n",
        "        :param boolean:\n",
        "        :param layername: depends on lib, for inception e.g. Conv2d_4a_3x3\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        # Stage-1: freeze all the layers\n",
        "        if layername is None:\n",
        "            for i, param in self.model.named_parameters():\n",
        "                param.requires_grad = True\n",
        "                return\n",
        "        else:\n",
        "            for i, param in self.model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "        if boolean:\n",
        "            # Make all layers following the layername layer trainable\n",
        "            ct = []\n",
        "            found = False\n",
        "            for name, child in self.model.named_children():\n",
        "                if layername in ct:\n",
        "                    found = True\n",
        "                    for params in child.parameters():\n",
        "                        params.requires_grad = True\n",
        "                ct.append(name)\n",
        "            if not found:\n",
        "                raise NotImplementedError('Layer not found, cant finetune!'.format(\n",
        "                    layername))\n",
        "        else:\n",
        "            if self.modelchoice == 'xception':\n",
        "                # Make fc trainable\n",
        "                for param in self.model.last_linear.parameters():\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            elif self.modelchoice in ['efficientB5','efficientB7']:\n",
        "                # Make fc trainable\n",
        "                for param in self.model._fc.parameters():\n",
        "                    param.requires_grad = True           \n",
        "            else:\n",
        "                # Make fc trainable\n",
        "                for param in self.model.fc.parameters():\n",
        "                    param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        #out, x = self.model(x)\n",
        "        out, x, map, type, mag = self.model(x)\n",
        "        if self.return_fea:\n",
        "            return out, x, map, type, mag\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "\n",
        "    def features(self, x):\n",
        "        x = self.model.features(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class RawXception(nn.Module):\n",
        "    \"\"\"\n",
        "    Untrained Xception Model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_out_classes=2, inc=3, dropout=0.0):\n",
        "        super(RawXception, self).__init__()\n",
        "\n",
        "        self.model = xception(pretrained=None, inc=inc)\n",
        "        # Replace fc\n",
        "        num_ftrs = self.model.last_linear.in_features\n",
        "        if not dropout:\n",
        "            self.model.last_linear = nn.Linear(num_ftrs, num_out_classes)\n",
        "        else:\n",
        "            print('Using dropout', dropout)\n",
        "            self.model.last_linear = nn.Sequential(\n",
        "                nn.Dropout(p=dropout),\n",
        "                nn.Linear(num_ftrs, num_out_classes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "    def features(self, x):\n",
        "        x = self.model.features(x)\n",
        "        return x\n",
        "\n",
        "    def classifier(self, x):\n",
        "        x = self.model.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def model_selection(modelname, num_out_classes,\n",
        "                    dropout=None):\n",
        "    \"\"\"\n",
        "    :param modelname:\n",
        "    :return: model, image size, pretraining<yes/no>, input_list\n",
        "    \"\"\"\n",
        "    if modelname == 'xception':\n",
        "        return TransferModel(modelchoice='xception',\n",
        "                             num_out_classes=num_out_classes)\n",
        "    elif modelname == 'resnet18':\n",
        "        return TransferModel(modelchoice='resnet18', dropout=dropout,\n",
        "                             num_out_classes=num_out_classes), \\\n",
        "            224, True, ['image'], None\n",
        "    else:\n",
        "        raise NotImplementedError(modelname)\n"
      ],
      "metadata": {
        "id": "MCpXSrFmME7O"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xmodel = model_selection('xception',2)\n",
        "print(Xmodel)\n",
        "Xmodel = Xmodel.eval()"
      ],
      "metadata": {
        "id": "UCJSX4-3MUUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pbPwYgCoMX5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as Data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_acc(outputs, labels):\n",
        "    \"\"\"计算acc\"\"\"\n",
        "    _, predict = torch.max(outputs.data, 1)\n",
        "    total_num = labels.shape[0]*1.0\n",
        "    correct_num = (labels == predict).sum().item()\n",
        "    acc = correct_num / total_num\n",
        "\n",
        "    return acc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = model_selection('xception',2).eval()\n",
        "\n",
        "# 优化器\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# 损失\n",
        "loss_fun = nn.CrossEntropyLoss()\n",
        "\n",
        "for e in range(10):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        optim.zero_grad()\n",
        "        out = model(x.float())\n",
        "        \n",
        "        y = y.type(torch.LongTensor)\n",
        "        loss = loss_fun(out, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        epoch_loss += loss.data\n",
        "        epoch_acc += get_acc(out, y)\n",
        "        \n",
        "\n",
        "    if e % 5 == 0:\n",
        "        print('epoch: %d, loss: %f, acc: %f' % (e, epoch_loss / 50, epoch_acc / 50))\n",
        "\n"
      ],
      "metadata": {
        "id": "qZX2R5zoMagi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),'/content/drive/MyDrive/classify_model.pkl')"
      ],
      "metadata": {
        "id": "wf9UwEGVMdj5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import floor\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import random\n",
        "\n",
        "# 注释为： 攻击类型 参数的意义 （取值范围） 有较明显观感差距的取值\n",
        "\n",
        "def GB(f,m): #高斯滤波 f为图片数组，m为高斯数组大小 5\n",
        "    return cv.GaussianBlur(f,(m,m),1)\n",
        "\n",
        "def AF(f,m): #中值滤波 f为图片数组，m为中值数组大小 5\n",
        "    return cv.medianBlur(f, m)\n",
        "\n",
        "def MF(f,m): #均值滤波 f为图片数组，m为均值数组大小 5\n",
        "    return cv.blur(f, (m,m))\n",
        "\n",
        "def JP(f,qual): #JPEG压缩 f为图片数组，qual为压缩质量，0-100 越高质量越好 50\n",
        "    f=f.astype(np.uint8)\n",
        "    cv.imwrite(\"temp.jpg\",f,[int(cv.IMWRITE_JPEG_QUALITY),qual])\n",
        "    return cv.imread(\"temp.jpg\")\n",
        "\n",
        "def CA(f,m): #对比度调节 f为图片数组，m为调节的对比度 -1-0-3  0.5\n",
        "    img=f.astype(np.float64)\n",
        "    out=img\n",
        "    MH=128\n",
        "    out=MH+(out-MH)*(1+m)\n",
        "    out[out<0]=0\n",
        "    out[out>255]=255\n",
        "    return out.astype(np.uint8)\n",
        "\n",
        "def CB(f,m): #亮度调节 f为图片数组，m为调节的亮度 百分比 -1-0-1 负数为降低亮度 正数增加  0.5\n",
        "    out=f.astype(np.float64)\n",
        "    out=out+m*255\n",
        "    out[out<0]=0\n",
        "    out[out>255]=255\n",
        "    return out.astype(np.uint8)\n",
        "\n",
        "def SC(f,m): #尺寸缩放 f为图片数组，m为调整的比例 百分比 0-1-正无穷 小于1为缩小，大于为放大 0.5\n",
        "    l=f.shape[0]\n",
        "    w=f.shape[1]\n",
        "    l=int(l*m)\n",
        "    w=int(w*m)\n",
        "    g=cv.resize(f,(w,l))\n",
        "    return g\n",
        "\n",
        "def DIBR_right(f,m): #向右偏移 f为图片数组，m为偏移的比例 0-1 0.05\n",
        "    m=m/4\n",
        "    l=f.shape[0]\n",
        "    w=f.shape[1]\n",
        "    wm=int(m*w)\n",
        "    g=f\n",
        "    a=np.round(np.linspace(1,wm,l//2)).astype(np.int32)\n",
        "    k=0\n",
        "    if np.ndim(f)==3:\n",
        "        temp=np.zeros((3,))\n",
        "        for i in range(l-l//2,l):\n",
        "            g[i,a[k]:w,:]=g[i,0:w-a[k],:]\n",
        "            g[i,0:a[k],:]=np.zeros((a[k],3))\n",
        "            k+=1\n",
        "    else:\n",
        "        for i in range(l-l//2,l):\n",
        "            g[i,a[k]:w]=g[i,0:w-a[k]]\n",
        "            g[i,0:a[k]]=np.zeros((a[k]))\n",
        "            k+=1\n",
        "    return g\n",
        "\n",
        "def DIBR_left(f,m): #向左偏移 f为图片数组，m为偏移的比例 0-1 0.05\n",
        "    m=m/4\n",
        "    l=f.shape[0]\n",
        "    w=f.shape[1]\n",
        "    wm=int(m*w)\n",
        "    g=f\n",
        "    a=np.round(np.linspace(1,wm,l//2)).astype(np.int32)\n",
        "    k=0\n",
        "    if np.ndim(f)==3:\n",
        "        temp=np.zeros((3,))\n",
        "        for i in range(l-l//2,l):\n",
        "            g[i,0:w-a[k],:]=g[i,a[k]:w,:]\n",
        "            g[i,w-a[k]:w,:]=np.zeros((a[k],3))\n",
        "            k+=1\n",
        "    else:\n",
        "        for i in range(l-l//2,l):\n",
        "            g[i,0:w-a[k]]=g[i,a[k]:w]\n",
        "            g[i,w-a[k]:w]=np.zeros((a[k]))\n",
        "            k+=1\n",
        "    return g\n",
        "\n",
        "def Rotation(f,angle): #旋转 f为图片数组，m为旋转角度 360°制 90\n",
        "    l=f.shape[0]\n",
        "    w=f.shape[1]\n",
        "    M=cv.getRotationMatrix2D((w//2,l//2),angle,1.0)\n",
        "    return cv.warpAffine(f,M,(w,l)) \n",
        "\n",
        "def Crop(f,m): #边缘剪切 f为图片数组，m为剪切的比例，0-1  0.2\n",
        "    if np.ndim(f)==3:\n",
        "        l,w,h=f.shape\n",
        "        m=m/2\n",
        "        sl=floor(l*m)\n",
        "        el=l-floor(l*m)\n",
        "        sw=floor(w*m)\n",
        "        ew=w-floor(w*m)\n",
        "        newf=np.zeros((l,w,h),dtype=np.uint8)\n",
        "        newf[sl:el,sw:ew]=f[sl:el,sw:ew]\n",
        "    else:\n",
        "        l,w=f.shape\n",
        "        m=m/2\n",
        "        sl=floor(l*m)\n",
        "        el=l-floor(l*m)\n",
        "        sw=floor(w*m)\n",
        "        ew=w-floor(w*m)\n",
        "        newf=np.zeros((l,w),dtype=np.uint8)\n",
        "        newf[sl:el,sw:ew]=f[sl:el,sw:ew]\n",
        "    return newf\n",
        "\n",
        "def SN(f,perce): #椒盐噪声 f为图片数组，perce为噪声密度 0-1 0.01\n",
        "    NoiseImg=f\n",
        "    NoiseNum=int(perce*f.shape[0]*f.shape[1])\n",
        "    for _ in range(NoiseNum):\n",
        "        randX=random.randint(0,f.shape[0]-1)\n",
        "        randY=random.randint(0,f.shape[1]-1)\n",
        "        if np.ndim(f)==3:\n",
        "            for i in range(3):\n",
        "                if random.randint(0,1)<=0.5:\n",
        "                    NoiseImg[randX,randY,i]=0\n",
        "                else:\n",
        "                    NoiseImg[randX,randY,i]=255\n",
        "        else:\n",
        "            if random.randint(0,1)<=0.5:\n",
        "                NoiseImg[randX,randY]=0\n",
        "            else:\n",
        "                NoiseImg[randX,randY]=255\n",
        "    return NoiseImg\n",
        "\n",
        "def GN(image,var): #高斯噪声 image为图片数组，var为高斯滤波方差 0.01\n",
        "    sigma=var**0.5\n",
        "    image=np.array(image/255, dtype=float)\n",
        "    noise = np.random.normal(0, sigma, image.shape)\n",
        "    out = image + noise \n",
        "    out[out<0]=0\n",
        "    out[out>1]=1\n",
        "    out = np.uint8(out*255)\n",
        "    return out\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "pzedgqJSMfb0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from symbol import parameters\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "\n",
        "def add_noise(picpath,savepath,famename):\n",
        "  \n",
        "    pic=cv.imread(picpath) #被攻击图片路径\n",
        "    list = [\"高斯模糊\",\"均值滤波\",\"中值滤波\",\"亮度变化\",\"对比度变化\",\"边缘剪切\",\"中心旋转\",\"高斯噪声\",\"椒盐噪声\",\"尺寸缩放\",\"DIBR左偏\",\"DIBR右偏\"]\n",
        "    path= savepath+str(famename)+'noise'+'.jpg'#存放攻击后图片路径\n",
        "    num = random.randint(0,11)\n",
        "    # num = 9\n",
        "   \n",
        "    type=list[num] #攻击类型 请参考下面的注释使用\n",
        "      \n",
        "    \n",
        "    # pic=cv.cvtColor(pic,cv.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 注释为： 攻击类型 参数的意义 （取值范围） 有较明显观感差距的取值\n",
        "    if type == \"高斯模糊\": \n",
        "        #高斯滤波 f为图片数组，m为高斯数组大小 5\n",
        "        parameter=5\n",
        "        pic = GB(pic, parameter)\n",
        "\n",
        "    elif type == \"均值滤波\":\n",
        "        #均值滤波 f为图片数组，m为均值数组大小 5\n",
        "        parameter=5\n",
        "        pic = MF(pic, parameter)\n",
        "    elif type == \"中值滤波\":\n",
        "        #中值滤波 f为图片数组，m为中值数组大小 5\n",
        "        parameter=5\n",
        "        pic = AF(pic, parameter)\n",
        "    elif type == \"亮度变化\":\n",
        "        #亮度调节 f为图片数组，m为调节的亮度 百分比 -1-0-1 负数为降低亮度 正数增加  0.5\n",
        "        parameter=0.5\n",
        "        pic = CB(pic, parameter)\n",
        "    elif type == \"对比度变化\":\n",
        "        #对比度调节 f为图片数组，m为调节的对比度 -1-0-3  0.5\n",
        "        parameter=0.5\n",
        "        pic = CA(pic, parameter)\n",
        "    elif type == \"边缘剪切\":\n",
        "        #边缘剪切(实际效果为被剪切的部分变黑,图片大小未变) f为图片数组，m为剪切的比例，0-1  0.2\n",
        "        parameter=0.2\n",
        "        pic = Crop(pic, parameter)\n",
        "    elif type == \"中心旋转\":\n",
        "        #旋转 f为图片数组，m为旋转角度 360°制 90\n",
        "        parameter=90\n",
        "        pic = Rotation(pic, parameter)\n",
        "    elif type == \"高斯噪声\":\n",
        "        #高斯噪声 image为图片数组，var为高斯滤波方差 0.01\n",
        "        parameter=0.01\n",
        "        pic = GN(pic, parameter)\n",
        "    elif type == \"椒盐噪声\":\n",
        "        #椒盐噪声 f为图片数组，perce为噪声密度 0-1 0.01\n",
        "        parameter=0.01\n",
        "        pic = SN(pic, parameter)\n",
        "    elif type == \"尺寸缩放\":\n",
        "        #尺寸缩放 f为图片数组，m为调整的比例 百分比 0-1-正无穷 小于1为缩小，大于为放大 0.5\n",
        "        parameter=0.5\n",
        "        pic = SC(pic, parameter)\n",
        "        #这里的DIBR仅为简易实现的左右像素偏移，慎用\n",
        "    elif type == \"DIBR左偏\": \n",
        "        #向左偏移 f为图片数组，m为偏移的比例 0-1 0.05\n",
        "        parameter=0.05\n",
        "        pic = DIBR_left(pic, parameter)\n",
        "    elif type == \"DIBR右偏\":\n",
        "        #向右偏移 f为图片数组，m为偏移的比例 0-1 0.05\n",
        "        parameter=0.05\n",
        "        pic = DIBR_right(pic, parameter)\n",
        "\n",
        "    #保存图片文件\n",
        "    cv.imwrite(path, pic)\n",
        "    img = cv2.imread(path)\n",
        "    return img,list[num]\n",
        "\n"
      ],
      "metadata": {
        "id": "oqj8t2JkMiK-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from google.colab.patches import cv2_imshow\n",
        "path_fake= \"/content/drive/MyDrive/original_face_img\"  #待读取的文件夹\n",
        "path_list_fake=os.listdir(path_fake)\n",
        "t1 = 0\n",
        "\n",
        "for filename in path_list_fake:\n",
        "            m = str(os.path.splitext(filename)[0])\n",
        "            img,n = add_noise(os.path.join(path_fake,filename),'/content/drive/MyDrive/original_noise/',m)\n",
        "            img = torch.tensor(img)\n",
        "            \n",
        "            img = torch.unsqueeze(img,0)\n",
        "            img = img.permute(0,3,1,2)\n",
        "            \n",
        "            # print(n)\n",
        "            # print(img.shape)\n",
        "            \n",
        "            # print(b.shape)\n",
        "            if n == '尺寸缩放':\n",
        "              for i in range(3):\n",
        "               # print(img[0,i,:,:].shape)\n",
        "               piece = img[0,i,:,:]\n",
        "               piece = piece.numpy() \n",
        "               # print(img)\n",
        "               temp = cv2.copyMakeBorder(piece,72,72,108,108,cv2.BORDER_REPLICATE)\n",
        "               temp = torch.tensor(temp)\n",
        "               temp = torch.unsqueeze(temp,0)\n",
        "               if i == 0:\n",
        "                 pic = temp\n",
        "               elif i != 0:\n",
        "                #  print(pic.shape)\n",
        "                 # print(temp.shape)\n",
        "                 pic = torch.cat((pic,temp),0)\n",
        "               i += 1\n",
        "              img = torch.unsqueeze(pic,0)\n",
        "              # print(img.shape)\n",
        "            if t1 == 0:\n",
        "              org_set_noise = img\n",
        "            elif t1 != 0:\n",
        "              org_set_noise = torch.cat((org_set_noise,img),0)\n",
        "            t1 += 1\n",
        "print(org_set_noise.shape)\n",
        "            "
      ],
      "metadata": {
        "id": "bipfRop8Mm8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "path_fake= \"/content/drive/MyDrive/fake_face_img\"  #待读取的文件夹\n",
        "path_list_fake=os.listdir(path_fake)\n",
        "t2 = 0\n",
        "for filename in path_list_fake:\n",
        "            m = str(os.path.splitext(filename)[0])\n",
        "            img,n = add_noise(os.path.join(path_fake,filename),'/content/drive/MyDrive/fake_noise/',m)\n",
        "            img = torch.tensor(img)\n",
        "            \n",
        "            img = torch.unsqueeze(img,0)\n",
        "            img = img.permute(0,3,1,2)\n",
        "            if n == '尺寸缩放':\n",
        "              for i in range(3):\n",
        "               # print(img[0,i,:,:].shape)\n",
        "               piece = img[0,i,:,:]\n",
        "               piece = piece.numpy() \n",
        "               # print(img)\n",
        "               temp = cv2.copyMakeBorder(piece,72,72,108,108,cv2.BORDER_REPLICATE)\n",
        "               temp = torch.tensor(temp)\n",
        "               temp = torch.unsqueeze(temp,0)\n",
        "               if i == 0:\n",
        "                 pic = temp\n",
        "               elif i != 0:\n",
        "                #  print(pic.shape)\n",
        "                 # print(temp.shape)\n",
        "                 pic = torch.cat((pic,temp),0)\n",
        "               i += 1\n",
        "              img = torch.unsqueeze(pic,0)\n",
        "              # print(img.shape)\n",
        "            if t2 == 0:\n",
        "             fake_set_noise = img\n",
        "            elif t2 != 0:\n",
        "              fake_set_noise = torch.cat((fake_set_noise,img),0)\n",
        "            t2 += 1\n",
        "print(fake_set_noise.shape)"
      ],
      "metadata": {
        "id": "CDzbOMr-Mo8I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}